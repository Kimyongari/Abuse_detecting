{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "150c2757-3491-4325-9c19-1d77c929e613",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "import warnings\n",
    "import random\n",
    "warnings.filterwarnings('ignore')\n",
    "import datetime\n",
    "\n",
    "import import_ipynb\n",
    "import abuse_detecting_preprocessing as pp\n",
    "import abuse_detecting_databuild as b\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import fasttext\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "_1DCNN_model = tf.keras.models.load_model('1DCNN_model.h5')\n",
    "BiLSTM_model = tf.keras.models.load_model('BiLSTM_model.h5')\n",
    "GRU_model = tf.keras.models.load_model('GRU_model.h5')\n",
    "fasttext_model = fasttext.load_model('/Users/kim-yongjun/Documents/abuse_detecting/fasttext_model.bin')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e631365e-61f0-4738-9c74-89569c896a19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def erase_bot(data):\n",
    "\n",
    "    # 첫 번째 열의 값이 '@'로 시작하는 행을 필터링하여 봇으로 간주하고 제거\n",
    "    idxs = data[data.str.startswith('@') == True].index\n",
    "    data.loc[idxs] = None\n",
    "    bot_cnt = len(idxs)\n",
    "    print('data.shape : ', data.shape, 'None 처리한 봇 수 : ', bot_cnt, '\\n')\n",
    "    return data\n",
    "# erase_bot 함수 사용 예시\n",
    "# data = erase_bot(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dd7cb96d-10e4-453a-bd37-df9f56c86646",
   "metadata": {},
   "outputs": [],
   "source": [
    "def null_finder(data): # 공백만 있는 메세지 제거\n",
    "    print('공백 제거 전\\n', data.isnull().value_counts())\n",
    "    data = data.dropna()\n",
    "    print('공백 제거 후 \\n', data.isnull().value_counts())\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "48cbd5ca-1e4e-4a33-9e3f-c3196ac0b170",
   "metadata": {},
   "outputs": [],
   "source": [
    "def erase_emoticons(data):\n",
    "# 이모티콘들이 대부분 ::smiling::으로 표시되기에 이 부분을 제거하고 이어 붙이는 작업을 수행.\n",
    "# ex) ::smiling:: 페이커 잘한다 > 페이커 잘한다 \n",
    "    cnt = 0\n",
    "    try:\n",
    "        cnt = 0\n",
    "        for i in range(len(data)):\n",
    "            if ':' in data[i]:\n",
    "                l = data[i].find(':')\n",
    "                r = data[i].rfind(':')\n",
    "                data[i] = data[i][:l] + data[i][r+1:]\n",
    "                cnt += 1\n",
    "    except Exception as e:\n",
    "        print(\"An error occurred:\", e)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5ef0c729-12eb-4c50-a87c-68930698f9f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def soft_ensemble(models, data): \n",
    "# 욕설 0 , 정상 1 / 세 모델 결과의 평균이 0.3 미만일 경우(확실한 경우)를 0 으로 라벨링\n",
    "# Pseudo labeled data를 만들기 위함.\n",
    "    pred = np.column_stack([m.predict(data) for m in models])\n",
    "    pred = np.mean(pred, axis = 1)\n",
    "    pred = np.array([0 if p <= 0.3 else 1 for p in pred])\n",
    "    return pred\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0e4bdba7-bddb-4207-9fda-f2da39be936a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def makesample(size):\n",
    "# 전체 데이터에서 size만큼의 크기의 데이터 추출\n",
    "    data = pd.DataFrame()\n",
    "    r = glob(os.getcwd() + '/chatting_datas/*.csv')\n",
    "    for i in r:\n",
    "        data = pd.concat([data, pd.read_csv(i)], ignore_index = True)\n",
    "        \n",
    "    df = data['message']\n",
    "    message = erase_bot(df)\n",
    "    message = null_finder(message)\n",
    "    message = erase_emoticons(message)\n",
    "    message = message.sample(size)\n",
    "    \n",
    "    vectors = b.making_x_train(message, embedding_length, fasttext_model, n_gram)\n",
    "    return message, vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e64183f0-5580-48f8-ac06-a8cb3d792fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def activation_learning_data(models, size):\n",
    "# 세 모델의 결과값 평균치가 0.3 이상 0.7 미만인 데이터들만 추출 (욕설인지 아닌지 애매한 데이터들)\n",
    "    m, vec = makesample(size)\n",
    "    pred = np.column_stack([m.predict(vec) for m in models])\n",
    "    pred = np.mean(pred, axis = 1)\n",
    "    pred = np.array([True if 0.3 <= p <= 0.7 else False for p in pred])\n",
    "    m = pd.DataFrame(m)\n",
    "    m['label'] = pred\n",
    "    target = m[m['label'] == True]\n",
    "    return target[['message']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "18d4b700-038e-45a1-9b72-c4f05cb05972",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data.shape :  (1007079,) None 처리한 봇 수 :  9367 \n",
      "\n",
      "공백 제거 전\n",
      " message\n",
      "False    997694\n",
      "True       9385\n",
      "Name: count, dtype: int64\n",
      "공백 제거 후 \n",
      " message\n",
      "False    997694\n",
      "Name: count, dtype: int64\n",
      "An error occurred: 63\n"
     ]
    }
   ],
   "source": [
    "models = [_1DCNN_model, BiLSTM_model, GRU_model]\n",
    "embedding_length = 40\n",
    "n_gram = 5\n",
    "size = 10000\n",
    "today = datetime.datetime.today().strftime(\"%Y_%m_%d_%H_%M\") \n",
    "messages, vec = makesample(size)\n",
    "messages = pd.DataFrame(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "d32e9360-bb95-4906-84f8-0556c2ae269e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2024_05_21_17_56'"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "today"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "fb133827-b499-4838-b8ea-b7f28a53644f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step\n"
     ]
    }
   ],
   "source": [
    "pseudo_labeled_data = soft_ensemble(models, vec)\n",
    "messages['label'] = pseudo_labeled_data\n",
    "messages.to_csv(os.getcwd() + f'/chatting_datas/labeled_datas/{today}_pseudo.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "a58f5f98-577d-4c17-8dbb-29c187f06d3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data.shape :  (1007079,) None 처리한 봇 수 :  9367 \n",
      "\n",
      "공백 제거 전\n",
      " message\n",
      "False    997694\n",
      "True       9385\n",
      "Name: count, dtype: int64\n",
      "공백 제거 후 \n",
      " message\n",
      "False    997694\n",
      "Name: count, dtype: int64\n",
      "An error occurred: 63\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step\n"
     ]
    }
   ],
   "source": [
    "act_data = activation_learning_data(models, 10000)\n",
    "act_data.to_csv(os.getcwd() + f'/chatting_datas/{today}_act_learning.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ad85b51-a039-481a-a76f-63b0ce6f34e2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
